{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_import = pd.read_csv('./test.csv')\n",
    "train_import = pd.read_csv('./train.csv')\n",
    "\n",
    "test = np.zeros((0,0))\n",
    "train = np.zeros((0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = [test_import, train_import]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    False\n",
      "Pclass         False\n",
      "Name           False\n",
      "Sex            False\n",
      "Age             True\n",
      "SibSp          False\n",
      "Parch          False\n",
      "Ticket         False\n",
      "Fare            True\n",
      "Cabin           True\n",
      "Embarked       False\n",
      "dtype: bool\n",
      "PassengerId    False\n",
      "Survived       False\n",
      "Pclass         False\n",
      "Name           False\n",
      "Sex            False\n",
      "Age             True\n",
      "SibSp          False\n",
      "Parch          False\n",
      "Ticket         False\n",
      "Fare           False\n",
      "Cabin           True\n",
      "Embarked        True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "for dataset in data_clean:\n",
    "    print(dataset.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_clean:\n",
    "    # datasets are missing data in Age, Fare, Cabin and Embarked\n",
    "    # inspect the data and clean up the data. Start with first column and work our way up\n",
    "    # Age and Fare we can fill by taking the median \n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n",
    "\n",
    "    # Embarked and Cabin we can fill with mode (most common)\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n",
    "    dataset['Cabin'].fillna(dataset['Cabin'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_clean:\n",
    "    # now that the data is filled we should see if there are columns that are irrelevant\n",
    "    # we can drop passengerId as its an index, also cabin and ticket are irrelevant combined with the other features that we already\n",
    "    # have such as fare.\n",
    "    dataset.drop(['PassengerId','Cabin', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_clean:\n",
    "    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n",
    "    \n",
    "    # set isAlone to 0 \n",
    "    dataset['IsAlone'] = 1\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 \n",
    "\n",
    "    # split title from remainder of the name\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    # group non common titles\n",
    "    title_names = (dataset['Title'].value_counts() < 10)\n",
    "    dataset['Title'] = dataset['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    \n",
    "    \n",
    "    # group some features down into groups\n",
    "    # create 4 different fare groups\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n",
    "    dataset['AgeBin'] = pd.qcut(dataset['Age'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "\n",
    "for dataset in data_clean:    \n",
    "    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n",
    "    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n",
    "    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n",
    "    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n",
    "\n",
    "    \n",
    "    featuresTest = ['Sex','Pclass', 'Embarked', 'Title','SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone']\n",
    "    featuresTrain = ['Survived','Sex','Pclass', 'Embarked', 'Title','SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone']\n",
    "    test = pd.get_dummies(data_clean[0][featuresTest])\n",
    "    train = pd.get_dummies(data_clean[1][featuresTrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('Survived', axis=1)\n",
    "Y_train = train['Survived'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8215849991506451\n"
     ]
    }
   ],
   "source": [
    "svc=make_pipeline(StandardScaler(),SVC(random_state=1))\n",
    "r=[0.0001,0.001,0.1,1,10,50,100]\n",
    "PSVM=[{'svc__C':r, 'svc__kernel':['linear']},\n",
    "      {'svc__C':r, 'svc__gamma':r, 'svc__kernel':['rbf']}]\n",
    "GSSVM=GridSearchCV(estimator=svc, param_grid=PSVM, scoring='accuracy', cv=2)\n",
    "scores_svm=cross_val_score(GSSVM, X_train.astype(float), Y_train,scoring='accuracy', cv=5)\n",
    "print(np.mean(scores_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a fresh set to get the ids from\n",
    "fresh_import = pd.read_csv('./test.csv')\n",
    "\n",
    "#Fit the model\n",
    "GSSVM.fit(X_train, Y_train)\n",
    "pred=GSSVM.predict(test)\n",
    "output=pd.DataFrame({'PassengerId':fresh_import['PassengerId'],'Survived':pred})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
